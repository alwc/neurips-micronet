{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:09:42.367962Z",
     "start_time": "2019-10-12T06:09:35.892337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from u import *\n",
    "from ut import *\n",
    "from data import *\n",
    "from quantized_model import evaluate, get_net\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import distiller\n",
    "\n",
    "from distiller.quantization import PostTrainLinearQuantizer, LinearQuantMode\n",
    "from copy import deepcopy\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "decoder = (Cache / 'vocab.npy').load()\n",
    "encoder = get_encoder(decoder)\n",
    "n_vocab = len(decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization Aware Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:09:47.398106Z",
     "start_time": "2019-10-12T06:09:46.743729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 124000\n",
      "Saved model /data/scratch/zxyan/micronet/wikitext-103/quant_aware,2/models/model-0.pth at step 0\n"
     ]
    }
   ],
   "source": [
    "c_base = Config(Wiki / 'shallow8_distill_1011_tgt40_agp_t175_lr0.0001', device='cuda', logger=False).load()\n",
    "c = deepcopy(c_base).var(res=Wiki / 'quant_aware,2').unvar(\n",
    "    'adaptive_ratio', 'pos_emb', 'hebbian', 'fix_softmax', 'hebbian_T', 'hebbian_gamma'\n",
    ")\n",
    "c = c.var(\n",
    "    model=Proj / 'quantized_model.py',\n",
    "    compress=c.res / 'distiller.yaml',\n",
    "    train_batch=1,\n",
    "    steps_per_epoch=1000,\n",
    "    step_warmup=0,\n",
    "    lr=0.0001,\n",
    "    step_eval=1,\n",
    ").save(True)\n",
    "state = c_base.load_state(124000)\n",
    "print('step', state['step'])\n",
    "# del state['amp']\n",
    "del state['opt']\n",
    "state['step'] = 0\n",
    "# state['opt']['param_groups'][0]['lr'] = 5e-4\n",
    "c.save_state(state['step'], state)\n",
    "(c.res._up / 'quant_aware/distiller.yaml').cp(c.res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T05:26:42.150153Z",
     "start_time": "2019-10-12T05:26:41.905192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at step 0\n"
     ]
    }
   ],
   "source": [
    "net = get_net(c)\n",
    "net, step = c.init_model(net, step='max', train=False)\n",
    "data_val = SequentialIterator(c, c.eval_batch, split='valid')\n",
    "print('Loaded model at step', step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:09:52.294360Z",
     "start_time": "2019-10-12T06:09:52.234380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd /data/scratch/zxyan/micronet/wikitext-103/quant_aware,2\n",
      "CUDA_VISIBLE_DEVICES=0 python3 ../../quantized_model.py . steps=1 opt_level=O0\n"
     ]
    }
   ],
   "source": [
    "print(c.train(env_gpu=0, steps=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T05:26:43.821689Z",
     "start_time": "2019-10-12T05:26:42.286187Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(c, data_val, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAT Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:11:53.744789Z",
     "start_time": "2019-10-12T06:11:53.457158Z"
    }
   },
   "outputs": [],
   "source": [
    "c = Config(Wiki / 'quant_aware,2').load()\n",
    "net = get_net(c)\n",
    "\n",
    "state = torch.load(c.res / 'models/model-1.pth')\n",
    "state = state['net']\n",
    "num_bits = 9\n",
    "max_int = 2 ** (num_bits - 1) - 1\n",
    "min_int = - 2 ** (num_bits - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:11:53.790878Z",
     "start_time": "2019-10-12T06:11:53.746356Z"
    }
   },
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def float_to_bin(num):\n",
    "    return bin(struct.unpack('!I', struct.pack('!f', num))[0])[2:].zfill(32)\n",
    "\n",
    "def bin_to_float(binary):\n",
    "    return struct.unpack('!f',struct.pack('!I', int(binary, 2)))[0]\n",
    "\n",
    "def get_fp_reduced(x, bits):\n",
    "    s = float_to_bin(x)\n",
    "    s = np.array(list(s))\n",
    "    s[bits:] = '0'\n",
    "    s = ''.join(s)\n",
    "    return bin_to_float(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:11:59.384695Z",
     "start_time": "2019-10-12T06:11:54.083620Z"
    }
   },
   "outputs": [],
   "source": [
    "new_state = OrderedDict()\n",
    "for k, p in net.named_modules():\n",
    "    if k + '.weight_scale' in state:\n",
    "        weight = state[k + '.weight']\n",
    "        weight_scale = state[k + '.weight_scale']\n",
    "        wq = (weight * weight_scale).round()\n",
    "        assert (wq - weight * weight_scale).abs().max() < 1e-4\n",
    "        assert ((min_int <= wq) & (wq <= max_int)).all()\n",
    "        weight_inv_scale = torch.tensor(\n",
    "            [get_fp_reduced(x, 32 - num_bits) for x in 1 / weight_scale.reshape(-1)]\n",
    "        ).reshape_as(weight_scale) # mantissa of weight_inv_scale has at most 32 - num_bits\n",
    "        new_weight = wq * weight_inv_scale # new weight is exactly representable in 32 bits\n",
    "        new_state[k + '.weight'] = new_weight\n",
    "    elif k + '.weight' in state:\n",
    "        new_state[k + '.weight'] = state[k + '.weight']\n",
    "    if k + '.bias' in state:\n",
    "        new_state[k + '.bias'] = state[k + '.bias']\n",
    "    if k + '.fake_q.scale' in state:\n",
    "        new_state[k + '.max_abs'] = torch.max(state[k + '.fake_q.tracked_max'].abs(), abs(state[k + '.fake_q.tracked_min'].abs()))\n",
    "        scale = state[k + '.fake_q.scale'] \n",
    "        inv_scale = get_fp_reduced(1 / scale, 32 - num_bits) # mantissa of inv_scale has at most 32 - num_bits\n",
    "        new_state[k + '.inv_scale'] = torch.tensor(inv_scale)\n",
    "    if k + '.pos_emb' in state:\n",
    "        new_state[k + '.pos_emb'] = state[k + '.pos_emb']\n",
    "for k in ['loss.cache_lambda_inv_sigmoid', 'loss.cache_theta_inv_softplus']:\n",
    "    new_state[k] = state[k]\n",
    "torch.save(new_state, c.res / 'models/model-1-processed.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running QAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T06:05:47.208377Z",
     "start_time": "2019-10-12T06:05:36.161768Z"
    }
   },
   "outputs": [],
   "source": [
    "c = Config(Wiki / 'quant_aware,3', device='cuda:0', distributed=False).load()\n",
    "import quantized_model\n",
    "quantized_model.distiller_vs_explicit = 'explicit'\n",
    "net = get_net(c)\n",
    "\n",
    "net.load_state_dict(\n",
    "    torch.load(c.res / 'models/model-1-processed.pth')\n",
    ")\n",
    "net = net.to(c.device)\n",
    "\n",
    "data_val = SequentialIterator(c, c.eval_batch, split='valid')\n",
    "data_test = SequentialIterator(c, c.eval_batch, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T02:35:56.946374Z",
     "start_time": "2019-10-12T02:35:52.035194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5340301990509033, 'perplexity': 34.26177149866618, 'time': 2.0}\n",
      "{'loss': 3.5535757541656494, 'perplexity': 34.93802417999064, 'time': 2.0}\n"
     ]
    }
   ],
   "source": [
    "net.cache_keys = net.cache_values = None\n",
    "print(evaluate(c, data_val, net))\n",
    "net.cache_keys = net.cache_values = None\n",
    "print(evaluate(c, data_test, net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:22:02.346233Z",
     "start_time": "2019-10-11T19:21:57.305054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model /data/scratch/zxyan/micronet/wikitext-103/quantization/models/model-0.pth at step 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/data/scratch/zxyan/micronet/wikitext-103/quantization/models/model-0.pth'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantization = (Wiki / 'quantization').mk()\n",
    "c_base = Config(Wiki / 'shallow8_cache_ppl33.20_tgt40_grad0_lr0.00010', device='cuda', logger=False).load()\n",
    "import copy\n",
    "c = copy.deepcopy(c_base).var(res=quantization).unvar(\n",
    "    'adaptive_ratio', 'pos_emb', 'hebbian', 'fix_softmax', 'hebbian_T', 'hebbian_gamma'\n",
    ")\n",
    "c = c.var(\n",
    "    model=Proj / 'quantized_model.py',\n",
    "    compress=c.res / 'distiller.yaml',\n",
    "    train_batch=9,\n",
    "    steps_per_epoch=1000,\n",
    "    step_warmup=0,\n",
    "    lr=0.0001\n",
    ").save(True)\n",
    "state = c_base.load_state('max')\n",
    "# del state['amp']\n",
    "del state['opt']\n",
    "state['step'] = 0\n",
    "# state['opt']['param_groups'][0]['lr'] = 5e-4\n",
    "c.save_state(state['step'], state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:22:03.598219Z",
     "start_time": "2019-10-11T19:22:02.350564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model at step 0\n"
     ]
    }
   ],
   "source": [
    "from quantized_model import get_net, evaluate\n",
    "from data import *\n",
    "data_val = SequentialIterator(c, c.eval_batch, split='valid')\n",
    "data_test = SequentialIterator(c, c.eval_batch, split='test')\n",
    "net = get_net(c)\n",
    "net, step = c.init_model(net, step='max', train=False)\n",
    "print('Loaded model at step', step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:22:08.928334Z",
     "start_time": "2019-10-11T19:22:03.599744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5211262702941895, 'perplexity': 33.822500297597784, 'time': 1.0}\n",
      "{'loss': 3.541309118270874, 'perplexity': 34.51207001194503, 'time': 1.0}\n"
     ]
    }
   ],
   "source": [
    "net.loss.cache_keys = net.loss.cache_values = None\n",
    "print(evaluate(c, data_val, net))\n",
    "net.loss.cache_keys = net.loss.cache_values = None\n",
    "print(evaluate(c, data_test, net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:24:19.511851Z",
     "start_time": "2019-10-11T19:24:11.533218Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import distiller\n",
    "from distiller.data_loggers import QuantCalibrationStatsCollector, collector_context\n",
    "\n",
    "distiller.utils.assign_layer_fq_names(net)\n",
    "collector = QuantCalibrationStatsCollector(net)\n",
    "\n",
    "pretr_stats = c.res / 'pretrained_stats.yaml'\n",
    "if not pretr_stats.exists():\n",
    "    with collector_context(collector) as collector:\n",
    "        evaluate(c, data_val, net)\n",
    "        collector.save(pretr_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:33:45.690340Z",
     "start_time": "2019-10-11T19:33:35.305645Z"
    }
   },
   "outputs": [],
   "source": [
    "overrides_yaml = \"\"\"\n",
    "embed.*:\n",
    "    fp16: true\n",
    "projection.*:\n",
    "    fp16: true\n",
    "\"\"\"\n",
    "overrides = distiller.utils.yaml_ordered_load(overrides_yaml)\n",
    "quantizer = PostTrainLinearQuantizer(\n",
    "    deepcopy(net),\n",
    "    model_activation_stats=pretr_stats,\n",
    "    bits_activations=32,\n",
    "    bits_parameters=32,\n",
    "    per_channel_wts=True,\n",
    "    mode=LinearQuantMode.ASYMMETRIC_SIGNED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T20:10:09.185449Z",
     "start_time": "2019-10-11T20:09:59.173459Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (embed): AdaptiveEmbedding(\n",
       "    (layers): ModuleList(\n",
       "      (0): Embedding(3500, 256)\n",
       "      (1): Embedding(21500, 64)\n",
       "      (2): Embedding(242735, 4)\n",
       "    )\n",
       "    (projections): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=256, bias=False)\n",
       "      (1): Linear(in_features=4, out_features=256, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout1): Dropout(p=0)\n",
       "  (layers): ModuleList(\n",
       "    (0): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "    (1): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "    (2): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "    (3): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "    (4): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "    (5): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "    (6): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "    (7): Decoder(\n",
       "      (ln1): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (qkv): Linear(in_features=256, out_features=576, bias=True)\n",
       "      (out): Linear(in_features=192, out_features=256, bias=False)\n",
       "      (dropout): Dropout(p=0)\n",
       "      (ln2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=768, bias=True)\n",
       "        (1): ReLU(inplace)\n",
       "        (2): Dropout(p=0)\n",
       "        (3): Linear(in_features=768, out_features=256, bias=True)\n",
       "        (4): Dropout(p=0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout2): Dropout(p=0)\n",
       "  (loss): ProjectedAdaptiveLogSoftmax(\n",
       "    (clusters): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=256, out_features=3500, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=21500, bias=True)\n",
       "      (2): Linear(in_features=4, out_features=242735, bias=True)\n",
       "    )\n",
       "    (projections): ModuleList(\n",
       "      (0): Linear(in_features=256, out_features=64, bias=False)\n",
       "      (1): Linear(in_features=256, out_features=4, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:33:56.125585Z",
     "start_time": "2019-10-11T19:33:47.069667Z"
    }
   },
   "outputs": [],
   "source": [
    "stats_before_prepare = deepcopy(quantizer.model_activation_stats)\n",
    "dummy_input = (torch.zeros(1, 1).long(),) * 2\n",
    "quantizer.prepare_model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:21:19.575312Z",
     "start_time": "2019-10-11T19:21:02.238746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.8828125, 'perplexity': 48.560599877464846, 'time': 3.0}\n",
      "{'loss': 3.90625, 'perplexity': 49.71218131735947, 'time': 4.0}\n"
     ]
    }
   ],
   "source": [
    "net.loss.cache_keys = net.loss.cache_values = None\n",
    "print(evaluate(c, data_val, net.half()))\n",
    "net.loss.cache_keys = net.loss.cache_values = None\n",
    "print(evaluate(c, data_test, net.half()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-11T19:34:03.478129Z",
     "start_time": "2019-10-11T19:33:56.426789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 16.36498260498047, 'perplexity': nan, 'time': 3.0}\n",
      "{'loss': 16.05936622619629, 'perplexity': nan, 'time': 3.0}\n"
     ]
    }
   ],
   "source": [
    "quantizer.model.loss.cache_keys = quantizer.model.loss.cache_values = None\n",
    "print(evaluate(c, data_val, quantizer.model))\n",
    "quantizer.model.loss.cache_keys = quantizer.model.loss.cache_values = None\n",
    "print(evaluate(c, data_test, quantizer.model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distiller",
   "language": "python",
   "name": "distiller"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
